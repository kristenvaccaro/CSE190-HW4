{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": false,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HhoaZMxrZXZ"
      },
      "source": [
        "# Automated Hate Speech Detection\n",
        "\n",
        "In this assignment you will design interactions around an automated hate speech detection system. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4NcLliIhFS8"
      },
      "source": [
        "_Attach a pdf with your sketches. Please include annotations/descriptions for each sketch._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nviFxr3-rZXj"
      },
      "source": [
        "## Part 1: Recourse (15 pts)\n",
        "\n",
        "Machine learning classifiers are often used to detect hate speech online. For example, the bot pictured below was designed by [Jasper Stephenson](https://www.jasperstephenson.com) to help manage abusive content on discord.\n",
        "![SafeSpaceBot](https://storage.googleapis.com/3lix-images/1rFcSntbispfYHagAX129_qcoHpbqfmsNn1P67Ncjg4I/kix.s5cl9igwh4bf-large.jpg) \n",
        "\n",
        "Suppose that you are designing an interface for a social media site. The machine learning team has already developed a hate speech detection model. \n",
        "\n",
        "Instead of simply banning users or content, your team wants to nudge users to improve their behavior. You are tasked with designing a way to warn users before they post content that the model deems harmful and to give them an opportunity to alter the offending content.\n",
        "\n",
        "**Provide three sketches and explain how your designs provide recourse to users.**\n",
        "\n",
        "*Each sketch is worth five points.*\n",
        "\n",
        "Please ensure each sketch does the following: \n",
        "\n",
        "- Articulate your goal or goals for the design. (1-2 sentences)\n",
        "- Specify which criteria for recourse (diverse, sparse, plausible, actionable) your design achieves and how it does so. (1-2 sentences)\n",
        "- Label your sketch. Indicate how your design provides recourse and where/how it achieves the criteria for recourse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wA-3EOSPU3A"
      },
      "source": [
        "## Part 2: Contestability (5 pts)\n",
        "\n",
        "Like all machine learning models, your team's hate speech classifier is imperfect and will make mistakes. Sometimes it will be an isolated incident. \n",
        "\n",
        "Sometimes it may be a systematic problem. For example, you might consistently miss a type of hate speech (e.g., hate speech towards a group that you didn't have in your training data or [for a group that your policy does not protect](https://www.propublica.org/article/facebook-hate-speech-censorship-internal-documents-algorithms)). Or you might consistently label something as hate speech when it's not (e.g., [when a community is reclaiming a term](https://www.npr.org/sections/publiceditor/2019/08/21/752330316/a-former-slur-is-reclaimed-and-listeners-have-mixed-feelings)). \n",
        "\n",
        "You are tasked with designing an interface to help users discover possible problems with the hate speech classifier and advocate for the social media platform to change how the classifier works.\n",
        "\n",
        "**Provide one sketch and explain how your design supports contestability.**\n",
        "\n",
        "Please ensure your sketch does the following:\n",
        "\n",
        "1. Articulate your goal or goals for your design. These goals should be specific, like a task or component of contestability that you will focus on. Contestability is defined as providing mechanisms for users to \"understand, construct, shape and challenge model predictions\". *As an example, you could choose to focus on the aspect of \"challenging\" the model and set the goal: \"build consensus in a community that the problem exists\".* \n",
        "\n",
        "2. Specify at least three criteria for someone to succeed at the goal. Note that unlike recourse, these criteria are not being defined in class. You should think about what appropriate criteria are. *As an example, if the goal you choose is \"building consensus in a community that the problem exists,\" you might define the criteria as: 1) focusing on concrete examples/instances of the problem, 2) providing a signal of how much agreement there is, 3) encouraging disagreements to be civil and constructive.* \n",
        "\n",
        "3. Label each sketch. Indicate where/how your design achieves the criteria identified above. \n",
        "\n",
        "*Note: Novel and creative approaches are encouraged.*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqQoEbKLIenK"
      },
      "source": [
        "If you are interested in this topic, feel free to stop by Mary Anne and/or Kristen's office hours to discuss our ongoing research project related to contestability."
      ]
    }
  ]
}